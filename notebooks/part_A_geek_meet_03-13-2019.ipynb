{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Wrangling with Python using Jupyter Notebooks\n",
    "\n",
    "### Geek Meet, March 13, 2019\n",
    "### Tom Madsen\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SAFETY MOMENT\n",
    "## IS THERE A REPRODUCIBILITY CRISIS?\n",
    "[1,500 Scientists Lift the Lid on Reproducibility (Nature, 2016)](https://www.nature.com/news/1-500-scientists-lift-the-lid-on-reproducibility-1.19970)\n",
    "\n",
    "<img src=\"../assets/is_there_reproducibility_crisis.jpeg\" width=600>__________<img src=\"../assets/reproducibility_by_field.jpg\" width=400>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## \"...I know I did some really useful analysis but I canâ€™t find it...\"\n",
    "\n",
    "[Building a Repeatable Data Analysis Process with Jupyter Notebooks (Practical Business Python, 2018)](https://pbpython.com/notebook-process.html)\n",
    "\n",
    "<img src=\"../assets/maze.jpg\" width=600>\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MY EXAMPLE\n",
    "\n",
    "## First, we were awarded a new project - a contaminated site that had a long investigative history and lots of data.\n",
    "\n",
    "## We got excel data tables from the previous consultant, in typical wide and un-tidied format.\n",
    "\n",
    "## Client asking us to evaluate and implement the cleanup at the site, which involves excavation and disposal of over 35,000 cubic yards of waste and contaminated soil.\n",
    "\n",
    "## We wanted soil quality data in a format that could be used for\n",
    "\n",
    "    1) Using 3D modeling to estimate volumes to be excavated\n",
    "    2) Look at correlations in constitutent concentrations and establish cleanup levels\n",
    "    \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HERE WE GO!\n",
    "\n",
    "<img src='../assets/never_do_live_demo.png' width=800>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setting up the Project\n",
    "\n",
    "- folders\n",
    "- notes file\n",
    "- locking down raw data (and a notes file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Python Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import datetime as dt\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in Raw Data Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph = pd.read_excel('../data/raw/Hydrocarbons Detected in Soils - 2013-2017.xlsx', sheet_name='TPH')[:367]\n",
    "tph.columns = ['sample_id','depth_ft', 'sample_date', 'dro','gro','oilgrease','trph']\n",
    "tph = tph.dropna(subset=['depth_ft','sample_date']).set_index('sample_id')\n",
    "tph.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voc = pd.read_excel('../data/raw/VOCs Detected in Soils - 2013-2017.xlsx', sheet_name='VOC')[:252]\n",
    "firstv3 = ['sample_id','depth_ft','sample_date']\n",
    "constitv = list(voc.iloc[0,3:])\n",
    "voc.columns = firstv3+constitv\n",
    "voc = voc.dropna(subset=['depth_ft','sample_date']).set_index('sample_id')\n",
    "voc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svoc = pd.read_excel('../data/raw/SemiVOCs Detected in Soils - 2013-2017.xlsx', \n",
    "                     sheet_name='Soil Data SVOCs')[:258]\n",
    "firsts3 = ['sample_id','depth_ft','sample_date']\n",
    "constits = list(svoc.iloc[0,3:])\n",
    "svoc.columns = firsts3+constits\n",
    "svoc = svoc.dropna(subset=['depth_ft','sample_date']).set_index('sample_id')\n",
    "svoc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svoc.loc['DC-B51  2.9-4.2', 'Acenaphthene':]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tph.shape)\n",
    "print(voc.shape)\n",
    "print(svoc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merge All Data Files by the Index (i.e., Sample_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc = tph.merge(voc.iloc[:,2:], how='left', left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc_svoc = tph_voc.merge(svoc.iloc[:,2:], how='left', left_index=True, right_index=True, suffixes=('_voc', '_svoc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc_svoc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tph_voc_svoc.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save File with All Data Combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save processed file\n",
    "now = dt.datetime.now()\n",
    "date = str(now)[:10]\n",
    "time = str(now.hour) + str(now.minute)\n",
    "proc_name ='../data/processed/all_data_uncleaned_{}_{}.xlsx'.format(date, time)\n",
    "tph_voc_svoc.to_excel(proc_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select COPCs for Residential and Industrial\n",
    "##### (based on comparison to RSLs and ISLs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(tph_voc_svoc.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From the draft RAWP and data summary:\n",
    "\n",
    "The ISL constituents are:  **benzene**, **toluene**, **ethylbenzene**, **xylenes**, **naphthalene**, **MTBE**, **gro**, **dro**, **O&G or TRPH**  \n",
    "\n",
    "As a point of reference and to confirm TPH-DRO is an indicator compound for remediation of the Site, the detected constituents were conservatively compared to the USEPA Regional Screening Levels (RSLs) for industrial land use.  The analysis showed that concentrations on-site are within, or more conservative than, a risk factor based on 10-6 and are protective of the environment.  The only VOCs detected above the USEPA Industrial RSLs were **naphthalene** and a **single detection of 1,2-dibromo-3-chloropropane** at depths of less than 8.5 feet.  The only SVOCs detected above the USEPA Industrial RSLs was **benzo(a)pyrene** at depths of less than 8.5 feet.  The base of the contaminated soil zone is predominately located within the wet sand layer, which is located above clean native silty clay soil.\n",
    "\n",
    "### Generate list of COPCs that have exceeded industrial and residential screening levels\n",
    "(also added sample depth and date columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copcs_resid = ['depth_ft','sample_date',\n",
    "               'dro','gro','oilgrease','trph','1,2-Dibromo-3-chloropropane','Benzene','Ethylbenzene','Toluene','Xylene (Total)','Methyl-tert-butyl ether','Naphthalene_voc',\n",
    "               '2-Methylnaphthalene',\n",
    "               'Benzo(a)anthracene','Benzo(a)pyrene','Benzo(b)fluoranthene','Benzyl alcohol','Indeno(1,2,3-cd)pyrene','Phenol','bis(2-Ethylhexyl)phthalate']\n",
    "copcs_indus = ['depth_ft','sample_date',\n",
    "               'dro','gro','oilgrease','trph','1,2-Dibromo-3-chloropropane','Benzene','Ethylbenzene','Toluene','Xylene (Total)','Methyl-tert-butyl ether','Naphthalene_voc',\n",
    "               'Benzo(a)anthracene','Benzo(a)pyrene']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copc_data_resid = tph_voc_svoc[copcs_resid]\n",
    "copc_data_indus = tph_voc_svoc[copcs_indus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copc_data_resid.loc['DC-B51  2.9-4.2',:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and Implement Helper Functions to Clean Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes commas in values\n",
    "def no_comma(value):\n",
    "    if ',' in str(value):\n",
    "        return value.replace(',','')\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts \"ND\" entries to 1.0 (ppm for TPH's and ppb for VOCs/SVOCs)\n",
    "def nd_to_1(value):\n",
    "    if value == 'ND':\n",
    "        return 1\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts \"<###.# XX\" entries to 1/2 the reporting limit\n",
    "def half_nd(value):\n",
    "    if '<' in str(value):\n",
    "        dl = value.split('<')[1].split(' ')[0] # works for '<430 3' and for '<6.1'\n",
    "        if type(dl) == 'float':\n",
    "            return dl/2\n",
    "        else:\n",
    "            return dl\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes \"J\" flags\n",
    "def no_j(value):\n",
    "    if 'J' in str(value):\n",
    "        val = value.split('J')[0]\n",
    "        if type(val) == 'float':\n",
    "            return val\n",
    "        else:\n",
    "            return float(val.split(',')[0])\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# deletes \"U\" flags\n",
    "def no_u(value):\n",
    "    if 'U' in str(value):\n",
    "        val = value.split('U')[0]\n",
    "        if type(val) == 'float':\n",
    "            return val\n",
    "        else:\n",
    "            return float(val.split(',')[0])\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes most superscripts, where there is a space between the value and the superscrips\n",
    "def no_ss(value):\n",
    "    if len(str(value).split(' ')) > 1:\n",
    "        val = str(value).split(' ')[0]\n",
    "        if type(val) == 'float':\n",
    "            return val\n",
    "        else:\n",
    "            return float(val.replace(',', ''))\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# removes superscript at the end of the value string - only occurs in one row for VOCs\n",
    "def no_ss1(value):\n",
    "    if chr(185) in str(value):\n",
    "        val = str(value).split(chr(185))[0]\n",
    "        if type(val) == 'float':\n",
    "            return val\n",
    "        else:\n",
    "            return float(val.replace(',', ''))\n",
    "    else:\n",
    "        return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test for no_ss1 function for finding superscript\n",
    "print(chr(185))\n",
    "value = '12,200' + chr(185)\n",
    "print(value)\n",
    "no_ss1(value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run all the helper functions and clean the data, and convert column data to numeric\n",
    "\n",
    "<img src='../assets/crossed_fingers.jpg'>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(df):\n",
    "    for col in df.columns[2:]:\n",
    "        df.loc[:,col] = df.loc[:,col].apply(no_comma)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(nd_to_1)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(half_nd)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(no_j)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(no_u)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(no_ss)\n",
    "        df.loc[:,col] = df.loc[:,col].apply(no_ss1)\n",
    "        df.loc[:,col] = pd.to_numeric(df[col],errors='raise')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copc_indus_clean = clean_data(copc_data_indus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copc_resid_clean = clean_data(copc_data_resid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save Cleaned Data to Processed Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save copc_indus_clean processed file\n",
    "now = dt.datetime.now()\n",
    "date = str(now)[:10]\n",
    "time = str(now.hour) + str(now.minute)\n",
    "proc_name ='../data/processed/copc_data_indus_cleaned_{}_{}.xlsx'.format(date, time)\n",
    "copc_indus_clean.to_excel(proc_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save copc_indus_clean processed file\n",
    "now = dt.datetime.now()\n",
    "date = str(now)[:10]\n",
    "time = str(now.hour) + str(now.minute)\n",
    "proc_name ='../data/processed/copc_data_resid_cleaned_{}_{}.xlsx'.format(date, time)\n",
    "copc_resid_clean.to_excel(proc_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Success!\n",
    "\n",
    "<img src='../assets/thumbs_up2.jpg' width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
